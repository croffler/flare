<!DOCTYPE html>
<html lang="en">
<head>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" href="../../css/prism.css"/>
<link rel="stylesheet" href="../../css/bootstrap.css"/>
<link rel="stylesheet" href="../../css/docs.css"/>
<link rel="stylesheet" href="../../css/hugo-bootswatch.css"/>
<title></title>
</head>
<body>
<h1 >RDD API</h1>
<hr>


<p>This section describes how to load data from the Data Grid to Spark.</p>

<h1 id="creating-the-data-grid-rdd">Creating the Data Grid RDD</h1>

<p>To load data from the Data Grid, use <code>SparkContext.gridRdd[R]</code>. The type parameter <code>R</code> is a Data Grid model class. For example,</p>

<div class="easyui-tabs" plain="true" data-options=""><div title="Scala" style="padding:10px"><pre><code class="language-scala">val products = sc.gridRdd[Product]()
</code></pre>
</div>
</div>






<p>Once RDD is created, you can perform any generic Spark actions or transformations, e.g.</p>

<div class="easyui-tabs" plain="true" data-options=""><div title="Scala" style="padding:10px"><pre><code class="language-scala">val products = sc.gridRdd[Product]()
println(products.count())
println(products.map(_.quantity).sum())
</code></pre>
</div>
</div>






<h1 id="saving-rdd-to-the-data-grid">Saving RDD to the Data Grid</h1>

<p>To save Spark RDD to the Data Grid, use <code>RDD.saveToGrid</code> method. It assumes that type parameter <code>T</code> of your <code>RDD[T]</code> is a Space class otherwise an exception will be thrown at runtime.</p>

<p>Example:</p>

<div class="easyui-tabs" plain="true" data-options=""><div title="Scala" style="padding:10px"><pre><code class="language-scala">val rdd = sc.parallelize(1 to 1000).map(i =&gt; Product(i, &quot;Description of product &quot; + i, Random.nextInt(10), Random.nextBoolean()))
rdd.saveToGrid()
</code></pre>
</div>
</div>






<h1 id="grid-side-rdd-filters">Grid-Side RDD Filters</h1>

<p>To query a subset of data from the Data Grid, use the <code>SparkContext.gridSql[R](sqlQuery, args)</code> method. The type parameter <code>R</code> is a Data Grid model class, the <code>sqlQuery</code>parameter is a native Data Grid SQL query, <code>args</code> are arguments for the SQL query. For example, to load only products with a quantity more than 10:</p>

<div class="easyui-tabs" plain="true" data-options=""><div title="Scala" style="padding:10px"><pre><code class="language-scala">val products = sc.gridSql[Product](&quot;quantity &gt; 10&quot;)
</code></pre>
</div>
</div>






<p>You can also bind parameters in the SQL query:</p>

<div class="easyui-tabs" plain="true" data-options=""><div title="Scala" style="padding:10px"><pre><code class="language-scala">val products = sc.gridSql[Product](&quot;quantity &gt; ? and featuredProduct = ?&quot;, Seq(10, true))
</code></pre>
</div>
</div>






<div class='bs-callout bs-callout-primary'>
<b style="">See also:</b><br>
<p>For more information about the Data Grid SQL queries, refer to <a href="./query-sql.html">Data Grid documentation</a>.</p>

</div> 

<h1 id="zip-rdd-with-grid-sql-data">Zip RDD with Grid SQL Data</h1>

<p>You may want to transform the RDD by executing SQL query for each element in the RDD. This can be done using <code>rdd.zipWithGridSql()</code> method. It returns a new RDD of tuple (element, query result items).
Note, this might be an expensive operation.</p>

<p>For example, you have RDD of Customers and want to associate them with their orders:</p>

<div class="easyui-tabs" plain="true" data-options=""><div title="Scala" style="padding:10px"><pre><code class="language-scala">val customers: RDD[Customer] = ...
val query = &quot;customerId = ?&quot;
val queryParamsConstructor = (c: Customer) =&gt; Seq(c.id)
val projections = None
val orders: RDD[(Customer, Seq[Order])] = customers.zipWithGridSql[Order](query, queryParamsConstructor, projections)

</code></pre>
</div>
</div>






<p><br></p>

<h1 id="controlling-spark-partitions">Controlling Spark partitions</h1>

<p>Methods <code>SparkContext.gridRdd()</code> and <code>SparkContext.gridSql()</code> take an optional <code>splitCount</code> parameter which defines the number of Spark partitions per Data Grid partition. This feature is limited to <code>bucketed</code> grid model.</p>

<div class='bs-callout bs-callout-primary'>
<b style="">See also:</b><br>
<p>For more information, refer to <a href="./insightedge-modeling.html">Data Modeling</a>.</p>

</div> 

</body>
<script src="../../js/prism.js"></script>
<script src="../../js/bootstrap.min.js"></script>
<script src="../../js/jquery-1.11.js"></script>
</html>