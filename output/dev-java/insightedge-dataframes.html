<!DOCTYPE html>
<html lang="en">
<head>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" href="../../css/prism.css"/>
<link rel="stylesheet" href="../../css/bootstrap.css"/>
<link rel="stylesheet" href="../../css/docs.css"/>
<link rel="stylesheet" href="../../css/hugo-bootswatch.css"/>
<title></title>
</head>
<body>
<h1 >Data Frames API</h1>
<hr>


<p>DataFrames provide an API for manipulating data within Spark. These provide a more user friendly experience than pure Scala for common queries.</p>

<div class='bs-callout bs-callout-primary'>
<b style="">See also:</b><br>
<p>To read more about DataFrames API, please refer to <a href="https://spark.apache.org/docs/latest/sql-programming-guide.html" target="_blank" >Spark Documentation <i class='fa fa-external-link'></i></a>.</p>

</div> 

<p>This section describes how to use the DataFrames API with the Data Grid.</p>

<h1 id="preparing">Preparing</h1>

<p>The entry point to Dataset features is Spark <code>SparkSession</code> (replaces the old <code>SQLContext</code>).</p>

<div class="easyui-tabs" plain="true" data-options=""><div title="Scala" style="padding:10px"><pre><code class="language-scala">import org.apache.spark.sql.SparkSession

val spark = SparkSession.builder().getOrCreate()

// For implicit conversions like converting RDDs to DataFrames to Dataset
import spark.implicits._
// This is used to simplify calling Data Grid features
import org.insightedge.spark.implicits.all._
</code></pre>
</div>
</div>






<h1 id="person-case-class">Person case class</h1>

<p>For the following code snippets, we will use a simple case class named Person.
This case class can be written to (and loaded from) the Data Grid or an external persisted storage.</p>

<div class="easyui-tabs" plain="true" data-options=""><div title="Scala" style="padding:10px"><pre><code class="language-scala">import org.insightedge.scala.annotation._
import scala.beans.BeanProperty

case class Person(
@BeanProperty @SpaceId(autoGenerate = true) var id: String,
@BeanProperty var name: String,
@BeanProperty var age: Int ) {

def this() = this(null, null, -1)
}
</code></pre>
</div>
</div>






<h1 id="creating-dataframes">Creating DataFrames</h1>

<p>RDDs are stored in Data Grid simply as collections of objects of a certain type. You can create DataFrame by such type with the next syntax:</p>

<div class="easyui-tabs" plain="true" data-options=""><div title="Using SQLContext" style="padding:10px"><pre><code class="language-scala">val spark: SparkSession // An existing SparkSession.

import org.insightedge.spark.implicits.all._

val df = spark.read.grid[Person]

// Displays the content of the DataFrame to stdout
df.show()
</code></pre>
</div>

<div title="SQL syntax" style="padding:10px"><pre><code class="language-scala">val spark: SparkSession // An existing SparkSession.

spark.sql(
s&quot;&quot;&quot;
|create temporary table people
|using org.apache.spark.sql.insightedge
|options (class &quot;${classOf[Person].getName}&quot;)
&quot;&quot;&quot;.stripMargin)

val df = spark.sql(&quot;select * from people&quot;)

// Displays the content of the DataFrame to stdout
df.show()
</code></pre>
</div>

<div title="Without imports" style="padding:10px"><pre><code class="language-scala">val spark: SparkSession // An existing SparkSession.

val df = spark.read
.format(&quot;org.apache.spark.sql.insightedge&quot;)
.option(&quot;class&quot;, classOf[Person].getName)
.load()

// Displays the content of the DataFrame to stdout
df.show()
</code></pre>
</div>
</div>







<div class='bs-callout bs-callout-warning'><p>If you want to load DataFrame from <code>SpaceDocuments</code> written form a third-party application, please, refer to <a href="#loading-custom-spacedocuments">section below</a></p>
</div>








<h1 id="persisting-dataframes-to-data-grid">Persisting DataFrames to Data Grid</h1>

<p>To write a DataFrame use <code>DataFrame.write</code>. The content of the DataFrame is saved with a specified collection name.
The behavior of the write operation is controlled by the <code>SaveMode</code>.</p>

<p>Since DataFrames are no longer linked to object type, the content of the DataFrame is persisted by the specified collection name.
Thus, when saving a DataFrame to the Data Grid, you must provide a collection name, and when loading persisted DataFrame,
the same collection name must be used instead of object type.</p>

<p>To persist and load persisted DataFrame you can use the following syntax:</p>

<div class="easyui-tabs" plain="true" data-options=""><div title="Simplified syntax" style="padding:10px"><pre><code class="language-scala">import org.insightedge.spark.implicits.all._

val spark: SparkSession // An existing SparkSession.
val df: DataFrame // An existing DataFrame

// Persist DataFrame into a collection named &quot;people&quot;
df.write.mode(SaveMode.Overwrite).grid(&quot;people&quot;)

// Load the DataFrame from the collection by name
val persisted = spark.read.grid(&quot;people&quot;)

// Displays the content of the DataFrame to stdout
persisted.show()
</code></pre>
</div>

<div title="Without imports" style="padding:10px"><pre><code class="language-scala">val spark: SparkSession // An existing SparkSession.
val df: DataFrame // An existing DataFrame

df.write
.format(&quot;org.apache.spark.sql.insightedge&quot;)
.mode(SaveMode.Overwrite)
.save(&quot;people&quot;)

val persisted = spark.read
.format(&quot;org.apache.spark.sql.insightedge&quot;)
.load(&quot;people&quot;)

// Displays the content of the DataFrame to stdout
persisted.show()
</code></pre>
</div>
</div>







<div class='bs-callout bs-callout-warning'><p>Nested properties are stored as <code>DocumentProperties</code> in Data Grid when DataFrame is persisted</p>
</div>








<p>Persisted DataFrames are shared among multiple Spark jobs and stay alive after the jobs are complete.</p>

<h1 id="nested-properties">Nested properties</h1>

<p>Let&rsquo;s enhance <code>Person</code> class with an additional property <code>Address</code> (that has some properties of it&rsquo;s own).</p>

<div class="easyui-tabs" plain="true" data-options=""><div title="Scala" style="padding:10px"><pre><code class="language-scala">import org.insightedge.scala.annotation._
import scala.beans.BeanProperty

case class Person(
@BeanProperty @SpaceId(autoGenerate = true) var id: String,
@BeanProperty var name: String,
@BeanProperty var age: Int,
@BeanProperty var address: Address ) {

def this() = this(null, null, -1, null) 
}

case class Address(city: String, state: String)
</code></pre>
</div>
</div>






<p>If you write some <code>Person</code> to a Data Grid, e.g. by persisting an RDD, and then load them as DataFrame,
you can see that DataFrame schema includes nested properties:</p>

<div class="easyui-tabs" plain="true" data-options=""><div title="Scala" style="padding:10px"><pre><code class="language-scala">import org.insightedge.spark.implicits.all._

val spark: SparkSession // An existing SparkSession.

val df = spark.read.grid[Person]

// Displays the schema of the DataFrame to stdout
df.printSchema()
</code></pre>
</div>
</div>






<p>This code will print the next schema:</p>

<pre><code>root
|-- id: string (nullable = true)
|-- name: string (nullable = true)
|-- age: integer (nullable = false)
|-- address: struct (nullable = true)
|    |-- city: string (nullable = true)
|    |-- state: string (nullable = true)
</code></pre>

<p>Nested properties can be accessed using dot-separated syntax, e.g. <code>address.city</code>. Here is an example of filtering by nested properties:</p>

<div class="easyui-tabs" plain="true" data-options=""><div title="Scala" style="padding:10px"><pre><code class="language-scala">val spark: SparkSession // An existing SparkSession.

val df = spark.read.grid[Person]
val countInBuffalo = df.filter(df(&quot;address.city&quot;) equalTo &quot;Buffalo&quot;).count()

// Displays number of people from Buffalo
println(countInBuffalo)
</code></pre>
</div>
</div>






<p>You can also unwrap the nested properties, thus changing the DataFrame schema:</p>

<div class="easyui-tabs" plain="true" data-options=""><div title="Scala" style="padding:10px"><pre><code class="language-scala">val spark: SparkSession // An existing SparkSession.

spark.read.grid[Person].createOrReplaceTempView(&quot;people&quot;)

val df = spark.sql(&quot;select address.city as city, address.state as state from people&quot;)
val countInBuffalo = df.filter(df(&quot;city&quot;) equalTo &quot;Buffalo&quot;).count()

// Displays the schema of the DataFrame to stdout
df.printSchema()

// Displays number of people from Buffalo
println(countInBuffalo)
</code></pre>
</div>
</div>






<p>This code will print the next DataFrame schema:</p>

<pre><code>root
|-- city: string (nullable = true)
|-- state: string (nullable = true)
</code></pre>


<div class='bs-callout bs-callout-warning'><p>When DataFrame is persisted, nested properties are stored as <code>DocumentProperties</code> in Data Grid</p>
</div>








<h1 id="controlling-spark-partitions">Controlling Spark partitions</h1>

<p>Similar to RDD in order to control the number of Spark partitions, set the <code>splitCount</code> option:</p>

<div class="easyui-tabs" plain="true" data-options=""><div title="Scala" style="padding:10px"><pre><code class="language-scala">val spark: SparkSession // An existing SparkSession.

val df = spark.read.option(&quot;splitCount&quot;, &quot;4&quot;).grid[Person]
</code></pre>
</div>
</div>






<p>The <code>splitCount</code> defines the number of Spark partitions per Data Grid partition. This feature is limited to <code>bucketed</code> grid model. Please, refer to <a href="./insightedge-modeling.html">Data Modeling</a> for more details.</p>

<h1 id="loading-custom-spacedocuments">Loading custom SpaceDocuments</h1>

<p>If you have a third-party application writing <code>SpaceDocuments</code> into the grid, you have to manually provide a schema for the DataFrame. Nested properties must be supplied with class metadata, so that DataFrame API can properly parse the <code>SpaceDocuments</code> (see the <code>address</code> field in the example below).</p>

<div class="easyui-tabs" plain="true" data-options=""><div title="Scala" style="padding:10px"><pre><code class="language-scala">import org.insightedge.spark.implicits.all._
import org.apache.spark.sql.types._

val addressType = StructType(Seq(
StructField(&quot;state&quot;, StringType, nullable = true),
StructField(&quot;city&quot;, StringType, nullable = true)
))

val schema = StructType(Seq(
StructField(&quot;personId&quot;, StringType, nullable = false),
StructField(&quot;name&quot;, StringType, nullable = true),
StructField(&quot;surname&quot;, StringType, nullable = true),
StructField(&quot;age&quot;, IntegerType, nullable = false),
StructField(&quot;address&quot;, addressType, nullable = true, nestedClass[Address])
))

val spark: SparkSession // An existing SparkSession.

val df = spark.read.schema(schema).grid(&quot;people&quot;)
</code></pre>
</div>
</div>






</body>
<script src="../../js/prism.js"></script>
<script src="../../js/bootstrap.min.js"></script>
<script src="../../js/jquery-1.11.js"></script>
</html>