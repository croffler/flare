<!DOCTYPE html>
<html lang="en">
<head>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" href="../../css/prism.css"/>
<link rel="stylesheet" href="../../css/bootstrap.css"/>
<link rel="stylesheet" href="../../css/docs.css"/>
<link rel="stylesheet" href="../../css/hugo-bootswatch.css"/>
<title></title>
</head>
<body>
<h1 >Developing Your First Application</h1>
<hr>


<p>This topic explains how to create an InsightEdge application that can read and write from/to the Data Grid. You should have a basic knowledge of <a href="http://spark.apache.org/docs/latest/index.html" target="_blank" >Apache Spark <i class='fa fa-external-link'></i></a>.</p>

<div class='bs-callout bs-callout-primary'>
<b style="">See also:</b><br>
<p>For instructions on how to install a minimum InsightEdge cluster setup and launch it, refer to <a href="./insightedge-local-setup.html">Starting InsightEdge</a>.</p>

</div> 

<h1 id="project-dependencies">Project Dependencies</h1>

<p>InsightEdge 12.3 runs on Spark 2.2.0 and Scala 2.11.8. These dependencies will be included when you depend on the InsightEdge artifacts.</p>

<p>InsightEdge .jars are not published to Maven Central Repository yet. To install Maven artifacts run the following command from the &lsquo;<XAP HOME>/insightedge/tools/maven&rsquo; directory:</p>

<pre><code class="language-bash">insightedge-maven
</code></pre>

<p>For SBT projects include the following:</p>

<pre><code class="language-bash">resolvers += Resolver.mavenLocal
resolvers += &quot;Openspaces Maven Repository&quot; at &quot;http://maven-repository.openspaces.org&quot;

libraryDependencies += &quot;org.gigaspaces.insightedge&quot; % &quot;insightedge-core&quot; % &quot;12.3.0-m18&quot; % &quot;provided&quot; exclude(&quot;javax.jms&quot;, &quot;jms&quot;)
</code></pre>

<p>And if you are building with Maven:</p>

<pre><code class="language-xml">&lt;dependency&gt;
&lt;groupId&gt;org.gigaspaces.insightedge&lt;/groupId&gt;
&lt;artifactId&gt;insightedge-core&lt;/artifactId&gt;
&lt;version&gt;12.3.0-m18&lt;/version&gt;
&lt;scope&gt;provided&lt;/scope&gt;
&lt;/dependency&gt;
</code></pre>


<div class='bs-callout bs-callout-info'>
<b style="">Info</b><br>
<p>InsightEdge .jars are already packed in the InsightEdge distribution, and are automatically loaded with your application if you submit them with <code>insightedge-submit</code> script or run the Web Notebook. As such, there is no need to pack them into your uber .jar. However, if you want to run Spark in <code>local[*]</code> mode, the dependencies should be declared with the <code>compile</code> scope.</p>
</div>





<h1 id="developing-a-spark-application">Developing a Spark Application</h1>

<p>InsightEdge provides an extension to the regular Spark API.</p>

<div class='bs-callout bs-callout-primary'>
<b style="">See also:</b><br>
<p>Read the <a href="http://spark.apache.org/docs/latest/quick-start.html#self-contained-applications" target="_blank" >Self-Contained Applications <i class='fa fa-external-link'></i></a> topic in the Apache Spark documentation if you are new to Spark.</p>

</div> 

<p><code>InsightEdgeConfig</code> is the starting point in connecting Spark with the Data Grid. Create the <code>InsightEdgeConfig</code> and the <code>SparkContext</code>:</p>

<div class="easyui-tabs" plain="true" data-options=""><div title="Scala" style="padding:10px"><pre><code class="language-scala">import org.insightedge.spark.context.InsightEdgeConfig
import org.insightedge.spark.implicits.all._

val sparkConf = new SparkConf()
.setAppName(&quot;sample-app&quot;)
.setMaster(&quot;spark://127.0.0.1:7077&quot;)
.setInsightEdgeConfig(InsightEdgeConfig(&quot;insightedge-space&quot;))
val sc = new SparkContext(sparkConf)
</code></pre>
</div>
</div>







<div class='bs-callout bs-callout-info'>
<b style="">Info</b><br>
<p>It is important to import <code>org.insightedge.spark.implicits.all._</code> to enable the Data Grid specific API.</p>

<p><code>insightedge-space</code> is the default Data Grid name that the demo mode starts automatically.</p>

<p>When you are running Spark applications from the Web Notebook, <code>InsightEdgeConfig</code> is created implicitly with the properties defined in the Spark interpreter.</p>
</div>





<h1 id="modeling-data-grid-objects">Modeling Data Grid Objects</h1>

<p>Create a case class <code>Product.scala</code> to represent a Product entity in the Data Grid:</p>

<pre><code class="language-scala">import org.insightedge.scala.annotation._
import scala.beans.{BeanProperty, BooleanBeanProperty}

case class Product(   
@BeanProperty @SpaceId var id: Long,
@BeanProperty var description: String,
@BeanProperty var quantity: Int,   
@BooleanBeanProperty var featuredProduct: Boolean
) {
def this() = this(-1, null, -1, false)
}
</code></pre>

<h1 id="saving-to-the-data-grid">Saving to the Data Grid</h1>

<p>To save a Spark RDD,  use the <code>saveToGrid</code> method.</p>

<pre><code class="language-scala">val rdd = sc.parallelize(1 to 1000).map(i =&gt; Product(i, &quot;Description of product &quot; + i, Random.nextInt(10), Random.nextBoolean()))
rdd.saveToGrid()
</code></pre>

<h1 id="loading-and-analyzing-data-from-the-data-grid">Loading and Analyzing Data from the Data Grid</h1>

<p>Use the <code>gridRdd</code> method of the <code>SparkContext</code> to view Data Grid objects as Spark RDDs.</p>

<pre><code class="language-scala">val gridRdd = sc.gridRdd[Product]()
println(&quot;total products quantity: &quot; + gridRdd.map(_.quantity).sum())
</code></pre>

<h1 id="closing-the-spark-context">Closing the Spark Context</h1>

<p>When you are done, close the Spark context and all connections to Data Grid with the following command:</p>

<pre><code class="language-scala">sc.stopInsightEdgeContext()
</code></pre>

<p>Under the hood, this will call the regular Spark <code>sc.stop()</code> command, so there is no need to call it manually.</p>

<h1 id="running-your-spark-application">Running your Spark Application</h1>

<p>After you have packaged a .jar, submit the Spark job via <code>insightedge-submit</code> located in <code>&lt;XAP Home&gt;/insightedge/bin</code> instead of <code>spark-submit</code> as follows:</p>

<pre><code class="language-bash">insightedge-submit --class com.insightedge.spark.example.YourMainClass --master spark://127.0.0.1:7077 path/to/jar/insightedge-examples.jar
</code></pre>

</body>
<script src="../../js/prism.js"></script>
<script src="../../js/bootstrap.min.js"></script>
<script src="../../js/jquery-1.11.js"></script>
</html>